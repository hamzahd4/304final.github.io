<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Ethics</title>
    <link rel="stylesheet" href="style.css">
</head>

    
<body>
    <header>
        <h1>Stakeholders</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="example1.html">Examples</a></li>
                <li><a href="ethics.html">Ethical Lenses</a></li>
                <li><a href="ethical_analysis.html">Ethical Analysis</a></li>
                <li><a href="Stakeholders.html" class="active">Stakeholders</a></li>
                <li><a href="workscited.html">Works Cited</a></li>
                

            </ul>
        </nav>
    </header>
    <main>
        <section>
            <h3>Who are the main audience of your ethical analysis?</h3>
            <p>The main audience of our ethical analysis includes:</p>
            <ul>
                <li>Software Developers  working with AI models</li>
                <li> Teachers and students  utilizing ChatGPT in for academic assistance and efficiency
                </li>
                <li> Healthcare Employees and Physicians  considering AI integration for administrative
                    support</li>
                <li> Business analysts and professionals  using AI to analyze data and conduct predictive
                    charts</li>
                <li> Policy makers and organizational leaders  deciding on AI usage guidelines and
                    conventions</li>
                <li> Society , especially users whose data or lives may be impacted by AI</li>
            

            <h3>Why should they care, and what should they do?</h3>
            <p>They should care because the rise of ChatGPT or generative AI is already changing how we work, learn,
                and communicate.</p>


            <p>Using a  utilitarian ethical lens , we recommend all stakeholders ensure that ChatGPT
                serves the greatest good. </p>
            <ul>
                <li> Developers:  Minimize bias, protect user data, and ensure transparency in AI design.
                </li>
                <li> Educators:  Encourage responsible AI use as a support tool—not a replacement for
                    learning.</li>
                <li> Businesses:  Apply AI ethically, ensuring human oversight and avoiding full reliance
                    on automation.</li>
                <li> Policy makers:  Enforce regulations that protect users and promote fair, ethical AI
                    integration.</li>
                <li>  End users:  Stay informed, question AI output, and use it as a tool—not a crutch.
                </li>
            </ul>
            <h3>What are  recommendations to the stakeholders who use and deploy the proposed technology?</h3>
            <p>I recommend that stakeholders take action by creating policies that protect people whose jobs are most at risk because of new technology, especially AI. There should be rules that require companies to make sure they aren’t just replacing workers without thinking about the consequences. Sectors like customer service, which rely heavily on human workers, should be given attention. Companies should be asked to offer training, support, or even new opportunities to workers whose jobs might be taken over by AI systems.Business owners, engineers, and AI developers should also take some responsibility.  </p>

        </section>
    </main>
</body>

</html>
